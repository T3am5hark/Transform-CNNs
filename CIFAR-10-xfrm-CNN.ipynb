{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.virtualenvs/gpu2/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from kerasutils import hits_and_misses, describe_model\n",
    "from imageutils import block_dct\n",
    "from imageutils import dataset_transform_block_dct\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX_orig, trainY_orig), (testX, testY) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to decimate training set size due to memory constraints?\n",
    "(trainX, testX_dummy, trainY, testY_dummy) = train_test_split(trainX_orig, trainY_orig, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37500, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "trainX = trainX / 255.0\n",
    "testX = testX / 255.0\n",
    "print(trainX.shape)\n",
    "print(testX.shape)\n",
    "print(trainX.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37500, 56, 56, 3)\n",
      "(10000, 56, 56, 3)\n"
     ]
    }
   ],
   "source": [
    "trainX = dataset_transform_block_dct(trainX,8,4)\n",
    "testX = dataset_transform_block_dct(testX,8,4)\n",
    "print(trainX.shape)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37500, 10)\n",
      "(10000, 10)\n",
      "56 56 3\n"
     ]
    }
   ],
   "source": [
    "# Transform labels from int to one-hot vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.fit_transform(testY)\n",
    "\n",
    "print(trainY.shape)\n",
    "print(testY.shape)\n",
    "n_classes = trainY.shape[1]\n",
    "height = trainX.shape[1]\n",
    "width = trainX.shape[2]\n",
    "channels = trainX.shape[3]\n",
    "\n",
    "print(height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Transform\" CNN architecture with Keras\n",
    "regularizer = regularizers.l2(0.003)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(height,width,channels), filters=64,  \n",
    "                 use_bias=True, kernel_size=(8,8), strides=8,\n",
    "                 kernel_regularizer=regularizer))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "#model.add(Conv2D(filters=192,use_bias=True, kernel_size=(3,3)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.4))\n",
    "model.add(Conv2D(filters=192,use_bias=True, kernel_size=(3,3),\n",
    "                 kernel_regularizer=regularizer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, kernel_regularizer=regularizer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "#model.add(Dense(128))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(128))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(lb.classes_.shape[0], activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deeper architecture\n",
    "# https://arxiv.org/pdf/1412.6806.pdf\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(height,width,channels), filters=64,  \n",
    "                 use_bias=True, kernel_size=(5,5), strides=8))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(filters=192, kernel_size=(3,3), strides=2))\n",
    "#model.add(Conv2D(filters=192, kernel_size=(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(n_classes, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DctGenerator:\n",
    "    def __init__(noise=0.1):\n",
    "        self.noise=noise\n",
    "    \n",
    "    def flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/50\n",
      "147/147 [==============================] - 34s 230ms/step - loss: 3.7534 - acc: 0.2168 - val_loss: 2.9024 - val_acc: 0.2100\n",
      "Epoch 2/50\n",
      "147/147 [==============================] - 33s 225ms/step - loss: 2.2238 - acc: 0.2984 - val_loss: 2.0284 - val_acc: 0.3332\n",
      "Epoch 3/50\n",
      "147/147 [==============================] - 33s 224ms/step - loss: 2.0065 - acc: 0.3317 - val_loss: 2.0958 - val_acc: 0.2972\n",
      "Epoch 4/50\n",
      "147/147 [==============================] - 33s 224ms/step - loss: 1.9196 - acc: 0.3587 - val_loss: 1.8495 - val_acc: 0.3853\n",
      "Epoch 5/50\n",
      "147/147 [==============================] - 33s 223ms/step - loss: 1.8824 - acc: 0.3745 - val_loss: 1.9753 - val_acc: 0.3476\n",
      "Epoch 6/50\n",
      "147/147 [==============================] - 33s 224ms/step - loss: 1.8340 - acc: 0.3909 - val_loss: 1.8587 - val_acc: 0.3810\n",
      "Epoch 7/50\n",
      "147/147 [==============================] - 33s 223ms/step - loss: 1.8080 - acc: 0.3991 - val_loss: 1.7701 - val_acc: 0.4195\n",
      "Epoch 8/50\n",
      "147/147 [==============================] - 33s 225ms/step - loss: 1.7998 - acc: 0.4068 - val_loss: 1.7225 - val_acc: 0.4341\n",
      "Epoch 9/50\n",
      "147/147 [==============================] - 33s 224ms/step - loss: 1.7842 - acc: 0.4109 - val_loss: 1.9206 - val_acc: 0.3768\n",
      "Epoch 10/50\n",
      "147/147 [==============================] - 33s 224ms/step - loss: 1.7744 - acc: 0.4161 - val_loss: 1.8719 - val_acc: 0.3746\n",
      "Epoch 11/50\n",
      "147/147 [==============================] - 33s 223ms/step - loss: 1.7687 - acc: 0.4174 - val_loss: 1.8221 - val_acc: 0.3964\n",
      "Epoch 12/50\n",
      "147/147 [==============================] - 33s 225ms/step - loss: 1.7679 - acc: 0.4209 - val_loss: 1.7581 - val_acc: 0.4320\n",
      "Epoch 13/50\n",
      "147/147 [==============================] - 33s 223ms/step - loss: 1.7495 - acc: 0.4255 - val_loss: 1.7124 - val_acc: 0.4434\n",
      "Epoch 14/50\n",
      "147/147 [==============================] - 33s 225ms/step - loss: 1.7464 - acc: 0.4325 - val_loss: 1.9414 - val_acc: 0.3628\n",
      "Epoch 15/50\n",
      "147/147 [==============================] - 33s 222ms/step - loss: 1.7494 - acc: 0.4267 - val_loss: 1.7519 - val_acc: 0.4320\n",
      "Epoch 16/50\n",
      "147/147 [==============================] - 33s 225ms/step - loss: 1.7404 - acc: 0.4351 - val_loss: 1.7592 - val_acc: 0.4244\n",
      "Epoch 17/50\n",
      "147/147 [==============================] - 33s 225ms/step - loss: 1.7364 - acc: 0.4382 - val_loss: 1.7020 - val_acc: 0.4523\n",
      "Epoch 18/50\n",
      "147/147 [==============================] - 33s 224ms/step - loss: 1.7369 - acc: 0.4376 - val_loss: 2.0579 - val_acc: 0.3442\n",
      "Epoch 19/50\n",
      "147/147 [==============================] - 33s 225ms/step - loss: 1.7320 - acc: 0.4376 - val_loss: 1.7804 - val_acc: 0.4243\n",
      "Epoch 20/50\n",
      "147/147 [==============================] - 33s 224ms/step - loss: 1.7255 - acc: 0.4383 - val_loss: 1.7983 - val_acc: 0.4175\n",
      "Epoch 21/50\n",
      "147/147 [==============================] - 33s 224ms/step - loss: 1.7291 - acc: 0.4395 - val_loss: 1.6960 - val_acc: 0.4506\n",
      "Epoch 22/50\n",
      "147/147 [==============================] - 33s 224ms/step - loss: 1.7254 - acc: 0.4442 - val_loss: 1.6410 - val_acc: 0.4693\n",
      "Epoch 23/50\n",
      " 82/147 [===============>..............] - ETA: 14s - loss: 1.7144 - acc: 0.4467"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-116c48ea0fb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                                  batch_size=batch_size),\n\u001b[1;32m     25\u001b[0m                                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                  validation_data=(testX, testY))\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done!!!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gpu2/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gpu2/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gpu2/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gpu2/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gpu2/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gpu2/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gpu2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gpu2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gpu2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gpu2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gpu2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/gpu2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 256\n",
    "\n",
    "print('Using real-time data augmentation.')\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    zoom_range=0.2,     # zoom image\n",
    "    rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(trainX)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model.fit_generator(datagen.flow(trainX, trainY,\n",
    "                                 batch_size=batch_size),\n",
    "                                 epochs=n_epochs,\n",
    "                                 validation_data=(testX, testY))\n",
    "\n",
    "print('Done!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37500 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "37500/37500 [==============================] - 8s 201us/step - loss: 1.1905 - acc: 0.7466 - val_loss: 1.4405 - val_acc: 0.6769\n",
      "Epoch 2/25\n",
      "37500/37500 [==============================] - 7s 196us/step - loss: 1.2213 - acc: 0.7404 - val_loss: 1.3308 - val_acc: 0.7064\n",
      "Epoch 3/25\n",
      "37500/37500 [==============================] - 7s 197us/step - loss: 1.2035 - acc: 0.7439 - val_loss: 1.3173 - val_acc: 0.7112\n",
      "Epoch 4/25\n",
      "37500/37500 [==============================] - 7s 198us/step - loss: 1.2055 - acc: 0.7445 - val_loss: 1.3018 - val_acc: 0.7146\n",
      "Epoch 5/25\n",
      "37500/37500 [==============================] - 7s 197us/step - loss: 1.2032 - acc: 0.7425 - val_loss: 1.2805 - val_acc: 0.7183\n",
      "Epoch 6/25\n",
      "37500/37500 [==============================] - 7s 196us/step - loss: 1.1975 - acc: 0.7470 - val_loss: 1.3357 - val_acc: 0.7030\n",
      "Epoch 7/25\n",
      "37500/37500 [==============================] - 7s 197us/step - loss: 1.2174 - acc: 0.7447 - val_loss: 1.4161 - val_acc: 0.6848\n",
      "Epoch 8/25\n",
      "37500/37500 [==============================] - 7s 196us/step - loss: 1.2158 - acc: 0.7441 - val_loss: 1.2825 - val_acc: 0.7208\n",
      "Epoch 9/25\n",
      "37500/37500 [==============================] - 7s 198us/step - loss: 1.2032 - acc: 0.7454 - val_loss: 1.2894 - val_acc: 0.7178\n",
      "Epoch 10/25\n",
      "37500/37500 [==============================] - 7s 198us/step - loss: 1.1985 - acc: 0.7449 - val_loss: 1.3436 - val_acc: 0.6984\n",
      "Epoch 11/25\n",
      "37500/37500 [==============================] - 7s 197us/step - loss: 1.2039 - acc: 0.7446 - val_loss: 1.2742 - val_acc: 0.7235\n",
      "Epoch 12/25\n",
      "37500/37500 [==============================] - 7s 196us/step - loss: 1.1911 - acc: 0.7487 - val_loss: 1.2918 - val_acc: 0.7180\n",
      "Epoch 13/25\n",
      "37500/37500 [==============================] - 7s 196us/step - loss: 1.1922 - acc: 0.7468 - val_loss: 1.3478 - val_acc: 0.6944\n",
      "Epoch 14/25\n",
      "37500/37500 [==============================] - 7s 197us/step - loss: 1.2074 - acc: 0.7446 - val_loss: 1.2686 - val_acc: 0.7224\n",
      "Epoch 15/25\n",
      "37500/37500 [==============================] - 7s 197us/step - loss: 1.1904 - acc: 0.7479 - val_loss: 1.3191 - val_acc: 0.7030\n",
      "Epoch 16/25\n",
      "37500/37500 [==============================] - 7s 198us/step - loss: 1.1936 - acc: 0.7484 - val_loss: 1.2860 - val_acc: 0.7186\n",
      "Epoch 17/25\n",
      "37500/37500 [==============================] - 7s 198us/step - loss: 1.1918 - acc: 0.7489 - val_loss: 1.2942 - val_acc: 0.7159\n",
      "Epoch 18/25\n",
      "37500/37500 [==============================] - 7s 198us/step - loss: 1.1989 - acc: 0.7452 - val_loss: 1.3295 - val_acc: 0.7084\n",
      "Epoch 19/25\n",
      "37500/37500 [==============================] - 7s 198us/step - loss: 1.2095 - acc: 0.7466 - val_loss: 1.2793 - val_acc: 0.7258\n",
      "Epoch 20/25\n",
      "37500/37500 [==============================] - 7s 196us/step - loss: 1.1918 - acc: 0.7498 - val_loss: 1.3843 - val_acc: 0.6976\n",
      "Epoch 21/25\n",
      "37500/37500 [==============================] - 7s 197us/step - loss: 1.2034 - acc: 0.7466 - val_loss: 1.3905 - val_acc: 0.6945\n",
      "Epoch 22/25\n",
      "37500/37500 [==============================] - 7s 197us/step - loss: 1.1978 - acc: 0.7490 - val_loss: 1.3154 - val_acc: 0.7078\n",
      "Epoch 23/25\n",
      "37500/37500 [==============================] - 7s 198us/step - loss: 1.2128 - acc: 0.7442 - val_loss: 1.3230 - val_acc: 0.7102\n",
      "Epoch 24/25\n",
      "37500/37500 [==============================] - 7s 196us/step - loss: 1.2057 - acc: 0.7458 - val_loss: 1.3407 - val_acc: 0.7064\n",
      "Epoch 25/25\n",
      "37500/37500 [==============================] - 7s 197us/step - loss: 1.1981 - acc: 0.7478 - val_loss: 1.3361 - val_acc: 0.7064\n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "batch_size = 256\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), \n",
    "              epochs=n_epochs, batch_size=batch_size)\n",
    "print('Done!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluating network...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.80      0.80      1000\n",
      "          1       0.89      0.84      0.86      1000\n",
      "          2       0.75      0.56      0.64      1000\n",
      "          3       0.60      0.56      0.58      1000\n",
      "          4       0.72      0.73      0.72      1000\n",
      "          5       0.64      0.68      0.66      1000\n",
      "          6       0.75      0.86      0.81      1000\n",
      "          7       0.80      0.78      0.79      1000\n",
      "          8       0.85      0.88      0.86      1000\n",
      "          9       0.78      0.87      0.82      1000\n",
      "\n",
      "avg / total       0.76      0.76      0.75     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate TEST model class prediction accuracy\n",
    "print(\"[INFO] Evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=batch_size)\n",
    "target_names = [str(x) for x in lb.classes_]\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "                            predictions.argmax(axis=1),\n",
    "                            target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluating network...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      3736\n",
      "          1       1.00      1.00      1.00      3715\n",
      "          2       1.00      0.98      0.99      3758\n",
      "          3       0.99      0.99      0.99      3770\n",
      "          4       0.98      0.99      0.99      3771\n",
      "          5       0.99      0.99      0.99      3723\n",
      "          6       0.99      1.00      1.00      3725\n",
      "          7       1.00      1.00      1.00      3760\n",
      "          8       1.00      1.00      1.00      3807\n",
      "          9       1.00      1.00      1.00      3735\n",
      "\n",
      "avg / total       0.99      0.99      0.99     37500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate TRAIN model class prediction accuracy\n",
    "print(\"[INFO] Evaluating network...\")\n",
    "trainPreds = model.predict(trainX, batch_size=batch_size)\n",
    "target_names = [str(x) for x in lb.classes_]\n",
    "print(classification_report(trainY.argmax(axis=1),\n",
    "                            trainPreds.argmax(axis=1),\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: <class 'keras.layers.convolutional.Conv2D'>\n",
      "    input=(None, 56, 56, 3)\n",
      "    output=(None, 7, 7, 256)\n",
      "    act=<function linear at 0x7f609834d1e0>\n",
      "    strides=(8, 8)\n",
      "Layer 1: <class 'keras.layers.core.Activation'>\n",
      "    input=(None, 7, 7, 256)\n",
      "    output=(None, 7, 7, 256)\n",
      "    act=<function relu at 0x7f60983bff28>\n",
      "Layer 2: <class 'keras.layers.core.Dropout'>\n",
      "    input=(None, 7, 7, 256)\n",
      "    output=(None, 7, 7, 256)\n",
      "    rate=0.5\n",
      "Layer 3: <class 'keras.layers.convolutional.Conv2D'>\n",
      "    input=(None, 7, 7, 256)\n",
      "    output=(None, 5, 5, 512)\n",
      "    act=<function linear at 0x7f609834d1e0>\n",
      "    strides=(1, 1)\n",
      "Layer 4: <class 'keras.layers.core.Activation'>\n",
      "    input=(None, 5, 5, 512)\n",
      "    output=(None, 5, 5, 512)\n",
      "    act=<function relu at 0x7f60983bff28>\n",
      "Layer 5: <class 'keras.layers.normalization.BatchNormalization'>\n",
      "    input=(None, 5, 5, 512)\n",
      "    output=(None, 5, 5, 512)\n",
      "Layer 6: <class 'keras.layers.core.Dropout'>\n",
      "    input=(None, 5, 5, 512)\n",
      "    output=(None, 5, 5, 512)\n",
      "    rate=0.5\n",
      "Layer 7: <class 'keras.layers.core.Flatten'>\n",
      "    input=(None, 5, 5, 512)\n",
      "    output=(None, 12800)\n",
      "Layer 8: <class 'keras.layers.core.Dense'>\n",
      "    input=(None, 12800)\n",
      "    output=(None, 256)\n",
      "    act=<function linear at 0x7f609834d1e0>\n",
      "Layer 9: <class 'keras.layers.core.Activation'>\n",
      "    input=(None, 256)\n",
      "    output=(None, 256)\n",
      "    act=<function relu at 0x7f60983bff28>\n",
      "Layer 10: <class 'keras.layers.core.Dropout'>\n",
      "    input=(None, 256)\n",
      "    output=(None, 256)\n",
      "    rate=0.5\n",
      "Layer 11: <class 'keras.layers.core.Dense'>\n",
      "    input=(None, 256)\n",
      "    output=(None, 10)\n",
      "    act=<function softmax at 0x7f60983bfc80>\n"
     ]
    }
   ],
   "source": [
    "describe_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "{'seed': None, 'noise_shape': None, 'rate': 0.1, 'trainable': True, 'name': 'dropout_1'}\n"
     ]
    }
   ],
   "source": [
    "layer = model.layers[2]\n",
    "layer.rate = 0.1\n",
    "\n",
    "print(layer.rate)\n",
    "print(layer.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6775 hits, 3225 misses (0.6775%)\n"
     ]
    }
   ],
   "source": [
    "preds = predictions.argmax(axis=1)\n",
    "targets = testY.argmax(axis=1)\n",
    "hits, misses = hits_and_misses(preds, targets)\n",
    "print('{0} hits, {1} misses ({2}%)'.format(len(hits), len(misses), len(hits)/float(len(predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 108x108 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0, Predicted: 3\n"
     ]
    }
   ],
   "source": [
    "# Look at examples of misses\n",
    "from imageutils import bgr2rgb\n",
    "idx = misses[random.randint(0,len(misses))]\n",
    "im = testX[idx]\n",
    "plt.figure(figsize=(1.5,1.5))\n",
    "plt.imshow(bgr2rgb(im))\n",
    "plt.show()\n",
    "print('Target: {0}, Predicted: {1}'.format(targets[idx], preds[idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 108x108 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 6, Predicted: 6\n"
     ]
    }
   ],
   "source": [
    "# Look at examples of hits\n",
    "from imageutils import bgr2rgb\n",
    "idx = hits[random.randint(0,len(hits))]\n",
    "im = testX[idx]\n",
    "plt.figure(figsize=(1.5,1.5))\n",
    "plt.imshow(bgr2rgb(im))\n",
    "plt.show()\n",
    "print('Target: {0}, Predicted: {1}'.format(targets[idx], preds[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
